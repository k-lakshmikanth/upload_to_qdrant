{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks = []\n",
    "doc_ids = []\n",
    "nodes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "qdrant_client = QdrantClient(\n",
    "    url=\"https://de17d8d3-22aa-4464-aec7-ab8792b5d72f.us-east4-0.gcp.cloud.qdrant.io:6333/\",\n",
    "    api_key=\"2xsy0iXGIzI8Fj_Fa7eiTRsb9fyl612Zl1Qm_i-9PpA2YucLSQLytw\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "text_parser = SentenceSplitter(chunk_size=512, chunk_overlap=100)\n",
    "embed_model = OllamaEmbedding(model_name='mxbai-embed-large', base_url='http://localhost:11434')\n",
    "\n",
    "Settings.embed_model = embed_model\n",
    "Settings.transformations = [text_parser]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers.file import PDFReader\n",
    "\n",
    "docs = PDFReader().load_data(r\"C:\\Users\\nokia\\Desktop\\Keerthi-X\\x physics em.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enumerating docs\n"
     ]
    }
   ],
   "source": [
    "print(\"enumerating docs\")\n",
    "for doc_idx, doc in enumerate(docs):\n",
    "    curr_text_chunks = text_parser.split_text(doc.text)\n",
    "    text_chunks.extend(curr_text_chunks)\n",
    "    doc_ids.extend([doc_idx] * len(curr_text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enumerating text_chunks\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.schema import TextNode\n",
    "\n",
    "print(\"enumerating text_chunks\")\n",
    "for idx, text_chunk in enumerate(text_chunks):\n",
    "    node = TextNode(text=text_chunk)\n",
    "    src_doc = docs[doc_ids[idx]]\n",
    "    node.metadata = src_doc.metadata\n",
    "    nodes.append(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of nodes : 408\n"
     ]
    }
   ],
   "source": [
    "print(f\"No. of nodes : {len(nodes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enumerating nodes\n",
      "Indexing 0\n",
      "Indexing 1\n",
      "Indexing 2\n",
      "Indexing 3\n",
      "Indexing 4\n",
      "Indexing 5\n",
      "Indexing 6\n",
      "Indexing 7\n",
      "Indexing 8\n",
      "Indexing 9\n",
      "Indexing 10\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.schema import MetadataMode\n",
    "\n",
    "print(\"enumerating nodes\")\n",
    "count = 0\n",
    "for node in nodes:\n",
    "    node_embedding = embed_model.get_text_embedding(\n",
    "        node.get_content(metadata_mode=MetadataMode.ALL)\n",
    "    )\n",
    "    node.embedding = node_embedding\n",
    "    print(f\"Indexing {count}\")\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext, VectorStoreIndex\n",
    "\n",
    "print(\"initializing the storage context\")\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "print(\"indexing the nodes in VectorStoreIndex\")\n",
    "index = VectorStoreIndex(\n",
    "    nodes=nodes,\n",
    "    storage_context=storage_context,\n",
    "    transformations=Settings.transformations,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
